---
phase: 02-large-project-performance
plan: 02
type: execute
wave: 1
depends_on: ["02-01"]
files_modified:
  - src/axon/core/ingestion/pipeline.py
  - tests/core/test_pipeline.py
autonomous: true
---

<objective>
## Goal
Add incremental indexing to `run_pipeline()`: when an existing index is present, skip unchanged files and only re-parse files whose content has changed, been added, or been deleted.

## Purpose
Walking + parsing account for 71% of total index time on the axon repo. On a 100k LOC project, these phases will dominate. Skipping unchanged files eliminates both costs for unchanged files on every subsequent `run_pipeline()` call — turning warm-start re-indexes from O(all files) to O(changed files).

## Output
- Modified `pipeline.py`: incremental branch in `run_pipeline()` using content-hash comparison
- Extended `tests/core/test_pipeline.py`: coverage for unchanged/changed/deleted/forced-full cases
</objective>

<context>
## Project Context
@.paul/PROJECT.md
@.paul/ROADMAP.md
@.paul/STATE.md

## Prior Work
@.paul/phases/02-large-project-performance/02-01-SUMMARY.md

## Source Files
@src/axon/core/ingestion/pipeline.py
@src/axon/core/storage/base.py
@tests/core/test_pipeline.py
</context>

<acceptance_criteria>

## AC-1: Unchanged files are skipped
```gherkin
Given storage has an existing index for a set of files
When run_pipeline() is called with full=False and no files have changed
Then result.incremental == True
And result.changed_files == 0
And result.files == total number of files discovered
```

## AC-2: Changed files are re-indexed
```gherkin
Given storage has an existing index, and one file's content has been modified
When run_pipeline() is called with full=False
Then result.incremental == True
And result.changed_files == 1
And the updated symbol from the changed file is queryable from storage
```

## AC-3: New files are indexed
```gherkin
Given storage has an existing index for N files, and a new file is added to the repo
When run_pipeline() is called with full=False
Then result.incremental == True
And result.changed_files == 1
And the new file's symbols are queryable from storage
```

## AC-4: Deleted files are removed
```gherkin
Given storage has an existing index including file F, and F is deleted from disk
When run_pipeline() is called with full=False
Then result.incremental == True
And storage no longer contains nodes for file F
```

## AC-5: full=True forces a complete re-index
```gherkin
Given storage has an existing index
When run_pipeline() is called with full=True
Then result.incremental == False
And all phases run (same behaviour as before this plan)
```

## AC-6: No storage skips incremental logic
```gherkin
Given storage=None
When run_pipeline() is called
Then result.incremental == False (unchanged)
And behaviour is identical to pre-plan
```

## AC-7: No regression
```gherkin
Given the existing test suite of 645 passing tests
When the test suite is run after changes
Then all 645 tests still pass
```

</acceptance_criteria>

<tasks>

<task type="auto">
  <name>Task 1: Implement incremental branch in run_pipeline()</name>
  <files>src/axon/core/ingestion/pipeline.py</files>
  <action>
    Add an incremental fast-path to `run_pipeline()`. The path activates when:
    - `storage is not None` AND
    - `full=False` AND
    - `storage.get_indexed_files()` returns a non-empty manifest (i.e., a prior index exists)

    Placement: immediately after `walk_repo()` completes and before `process_structure()`.

    Steps:
    1. Add `import hashlib` at the top of the file.
    2. After walk_repo() fills `files`, call `storage.get_indexed_files()` to get
       `manifest: dict[str, str]` (path → sha256).
    3. If `manifest` is non-empty (existing index):
       a. Compute `current: dict[str, str]` = sha256 of each FileEntry's content.
          Use: `hashlib.sha256(entry.content.encode()).hexdigest()`
       b. Partition:
          - `changed_or_new`: FileEntry objects where `current[e.path] != manifest.get(e.path)`
          - `deleted_paths`: paths in manifest but not in current keys
          - Unchanged: all others (skip entirely)
       c. Remove deleted: `storage.remove_nodes_by_file(path)` for each deleted_path.
       d. If `changed_or_new` is non-empty: call `reindex_files(changed_or_new, repo_path, storage)`.
          Then if `embeddings=True`, embed the partial graph:
          - Call `embed_graph(partial_graph)` and `storage.store_embeddings(node_embeddings)`
          - Wrap in try/except same as the full path (log warning on failure, don't raise)
       e. Populate result:
          - `result.incremental = True`
          - `result.changed_files = len(changed_or_new) + len(deleted_paths)`
          - `result.files = len(files)`
          - `result.symbols` and `result.relationships` are not re-counted (leave at 0 for incremental — they're not meaningful for a partial run)
          - `result.duration_seconds = time.monotonic() - start`
       f. Early return: `return KnowledgeGraph(), result`

    If `manifest` is empty (no prior index): fall through to the existing full-index path as before.

    Do NOT change the full-index path or any other existing behaviour.
    Do NOT add any helper functions — keep the logic inline in run_pipeline().
    Do NOT change reindex_files() or any other function.
  </action>
  <verify>
    uv run python -c "
from pathlib import Path
from axon.core.ingestion.pipeline import run_pipeline
from axon.core.storage.kuzu_backend import KuzuBackend
import tempfile, os

# Create a tiny repo and index it twice
with tempfile.TemporaryDirectory() as d:
    repo = Path(d)
    f = repo / 'hello.py'
    f.write_text('def greet(): pass\n')

    db_path = repo / '.axon'
    s = KuzuBackend()
    s.initialize(db_path)

    # First full index
    _, r1 = run_pipeline(repo, s, embeddings=False)
    assert not r1.incremental, f'First run should not be incremental: {r1.incremental}'

    # Second call, same files — should be incremental with 0 changes
    _, r2 = run_pipeline(repo, s, embeddings=False)
    assert r2.incremental, f'Second run should be incremental: {r2.incremental}'
    assert r2.changed_files == 0, f'No changes expected: {r2.changed_files}'

    # Modify the file — should detect 1 change
    f.write_text('def greet(): return \"hi\"\n')
    _, r3 = run_pipeline(repo, s, embeddings=False)
    assert r3.incremental, f'Third run should be incremental: {r3.incremental}'
    assert r3.changed_files == 1, f'One change expected: {r3.changed_files}'

    s.close()
    print('All assertions passed')
"
  </verify>
  <done>AC-1, AC-2, AC-3, AC-4, AC-5, AC-6 satisfied</done>
</task>

<task type="auto">
  <name>Task 2: Add incremental indexing tests</name>
  <files>tests/core/test_pipeline.py</files>
  <action>
    Add a new test class `TestIncrementalPipeline` to the existing test file.
    Read the file first to understand fixtures and imports. Re-use existing fixtures
    (`tmp_repo`, `storage`) from the same file.

    Tests to add (all in the new class):

    1. `test_incremental_no_changes`:
       - Run pipeline once (full index). Run again immediately.
       - Assert second result: `incremental == True`, `changed_files == 0`.

    2. `test_incremental_changed_file`:
       - Run pipeline. Modify a file's content (overwrite with new text).
       - Run pipeline again.
       - Assert: `incremental == True`, `changed_files == 1`.

    3. `test_incremental_new_file`:
       - Run pipeline. Write a NEW .py file with a new function.
       - Run pipeline again.
       - Assert: `incremental == True`, `changed_files == 1`.

    4. `test_incremental_deleted_file`:
       - Run pipeline. Delete one file.
       - Run pipeline again.
       - Assert: `incremental == True`, `changed_files == 1`.
       - Query storage to confirm no nodes remain for deleted file path.

    5. `test_full_flag_bypasses_incremental`:
       - Run pipeline. Run again with `full=True`.
       - Assert second result: `incremental == False`.

    All tests: pass `embeddings=False` to skip fastembed for speed.
    Use `tmp_repo` and a fresh `KuzuBackend` storage fixture.

    Do NOT modify any existing test or fixture.
  </action>
  <verify>uv run pytest tests/core/test_pipeline.py::TestIncrementalPipeline -v 2>&1 | tail -20</verify>
  <done>AC-1 through AC-7 satisfied: new tests pass, suite stays at 645+5 passing</done>
</task>

</tasks>

<boundaries>

## DO NOT CHANGE
- `src/axon/core/storage/kuzu_backend.py` — `get_indexed_files()` already works correctly
- `src/axon/core/storage/base.py` — protocol is stable
- `reindex_files()` in `pipeline.py` — already correct, do not modify
- `build_graph()` in `pipeline.py` — leave untouched
- Any existing test or fixture in `tests/core/test_pipeline.py`

## SCOPE LIMITS
- No global phases (community detection, dead code, coupling) in the incremental path — same as watcher behaviour
- No manifest stored separately on disk — use `get_indexed_files()` which reads from the existing DB
- No mtime-based comparison — use content hash (sha256) for correctness
- No changes to the CLI or MCP server — those call `run_pipeline()` and will benefit automatically

</boundaries>

<verification>
Before declaring plan complete:
- [ ] `uv run pytest tests/core/test_pipeline.py -v` — all tests pass (existing 34 + new 5)
- [ ] `uv run pytest` — full suite 650 passing, 0 failures
- [ ] Manual smoke: run pipeline twice on axon repo, second run shows `incremental=True` in benchmark output
</verification>

<success_criteria>
- All 5 new tests pass
- No regressions (full test suite green)
- `run_pipeline()` returns `result.incremental = True` on a warm-start call with unchanged files
- Code change is entirely in `pipeline.py` (≤ 30 new lines) and `test_pipeline.py` (≤ 80 new lines)
</success_criteria>

<output>
After completion, create `.paul/phases/02-large-project-performance/02-02-SUMMARY.md`
</output>
