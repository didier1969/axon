---
phase: 01-consolidation-and-scale
plan: 03
type: execute
wave: 1
depends_on: ["01-02"]
files_modified:
  - src/axon/core/parsers/markdown.py
  - src/axon/core/parsers/go_lang.py
  - src/axon/core/parsers/yaml_lang.py
  - src/axon/core/parsers/sql_lang.py
  - src/axon/core/parsers/html_lang.py
  - src/axon/core/parsers/css_lang.py
  - src/axon/core/parsers/__init__.py
  - src/axon/core/ingestion/parser_phase.py
  - src/axon/config/languages.py
  - pyproject.toml
  - tests/core/parsers/test_markdown.py
  - tests/core/parsers/test_go.py
  - tests/core/parsers/test_yaml.py
  - tests/core/parsers/test_sql.py
  - tests/core/parsers/test_html.py
  - tests/core/parsers/test_css.py
autonomous: true
---

<objective>
## Goal
Upgrade the Markdown parser from regex to tree-sitter with frontmatter and table extraction, and add 5 new language parsers (Go, YAML/TOML, SQL, HTML/CSS) to reach 12 supported languages.

## Purpose
Axon currently supports 6 languages (Python, TypeScript, JavaScript, Elixir, Rust, Markdown). Expanding to 12 makes it useful for most polyglot codebases. The Markdown parser needs tree-sitter for robust heading/section parsing and YAML frontmatter extraction (critical for docs-heavy repos).

## Output
- Markdown parser rewritten with tree-sitter-markdown + frontmatter extraction
- 5 new parser files: go_lang.py, yaml_lang.py, sql_lang.py, html_lang.py, css_lang.py
- All parsers registered in parser_phase.py and languages.py
- 6 new tree-sitter grammar dependencies in pyproject.toml
- Tests for each new parser
- Total: 12 languages supported
</objective>

<context>
## Project Context
@.paul/PROJECT.md
@.paul/ROADMAP.md
@.paul/STATE.md

## Source Files
@src/axon/core/parsers/base.py
@src/axon/core/parsers/markdown.py
@src/axon/core/parsers/rust_lang.py (template for new tree-sitter parsers)
@src/axon/core/ingestion/parser_phase.py
@src/axon/config/languages.py
</context>

<acceptance_criteria>

## AC-1: Markdown parser uses tree-sitter with frontmatter
```gherkin
Given a Markdown file with YAML frontmatter (--- delimited) and headings
When parsed by MarkdownParser
Then headings are extracted as SymbolInfo(kind="section") with correct start/end lines
And YAML frontmatter keys are extracted as SymbolInfo(kind="function", name="frontmatter:{key}")
And Markdown links still produce ImportInfo
And code fence language tags still produce CallInfo
And existing Markdown tests pass (section extraction, links, code fences)
```

## AC-2: Markdown tables extracted
```gherkin
Given a Markdown file containing pipe-delimited tables
When parsed by MarkdownParser
Then each table is extracted as a SymbolInfo(kind="section", name="table:{first-column-header}")
```

## AC-3: Go parser extracts functions, structs, interfaces, imports
```gherkin
Given a Go source file with functions, structs, interfaces, and import statements
When parsed by GoParser
Then functions → SymbolInfo(kind="function")
And struct definitions → SymbolInfo(kind="struct")
And interface definitions → SymbolInfo(kind="interface")
And methods (func (receiver) name()) → SymbolInfo(kind="method", class_name=receiver_type)
And import statements → ImportInfo
And function calls → CallInfo
```

## AC-4: YAML/TOML parser extracts top-level keys
```gherkin
Given a YAML file with top-level mapping keys and nested structure
When parsed by YamlParser
Then top-level keys → SymbolInfo(kind="function", name=key)
And nested keys at depth 1 → SymbolInfo(kind="function", name="parent.child")
And .toml files also parse correctly via the same parser logic
```

## AC-5: SQL parser extracts DDL objects
```gherkin
Given a SQL file with CREATE TABLE, CREATE VIEW, CREATE FUNCTION statements
When parsed by SqlParser
Then each CREATE TABLE → SymbolInfo(kind="class", name=table_name)
And each CREATE VIEW → SymbolInfo(kind="function", name=view_name)
And each CREATE FUNCTION/PROCEDURE → SymbolInfo(kind="function", name=func_name)
```

## AC-6: HTML parser extracts elements with IDs and links
```gherkin
Given an HTML file with elements having id attributes and link/script tags
When parsed by HtmlParser
Then elements with id → SymbolInfo(kind="function", name=id_value)
And <script src="..."> → ImportInfo(module=src)
And <link href="..."> → ImportInfo(module=href)
And <a href="..."> → CallInfo (internal navigation)
```

## AC-7: CSS parser extracts selectors
```gherkin
Given a CSS file with class selectors, ID selectors, and @import rules
When parsed by CssParser
Then ID selectors (#name) → SymbolInfo(kind="function", name=selector)
And class selectors (.name) → SymbolInfo(kind="function", name=selector)
And @import rules → ImportInfo(module=url)
```

## AC-8: All languages registered and tests pass
```gherkin
Given the updated languages.py with all new extensions
When running the full test suite
Then all 687+ existing tests pass
And all new parser tests pass
And `get_parser()` works for go, yaml, toml, sql, html, css
```

</acceptance_criteria>

<tasks>

<task type="auto">
  <name>Task 1: Upgrade Markdown parser to tree-sitter with frontmatter and tables</name>
  <files>src/axon/core/parsers/markdown.py, pyproject.toml, tests/core/parsers/test_markdown.py</files>
  <action>
    Rewrite MarkdownParser using tree-sitter-markdown:

    1. Add `tree-sitter-markdown` to pyproject.toml dependencies
    2. Rewrite `markdown.py`:
       - Import: `import tree_sitter_markdown as tsmd`
       - Create language: `MD_LANGUAGE = Language(tsmd.language())`
       - Use tree-sitter to parse headings (atx_heading nodes) instead of regex
       - Keep section span logic (heading to next heading)
       - Extract YAML frontmatter (lines between first `---` pair before any content):
         - Parse YAML keys manually (split lines, extract `key:` patterns)
         - Each key → SymbolInfo(kind="function", name=f"frontmatter:{key}")
       - Extract pipe tables: find lines matching `|...|...|` pattern, group consecutive table lines
         - Each table → SymbolInfo(kind="section", name=f"table:{first_col_header}")
       - Keep link extraction (Markdown links → ImportInfo)
       - Keep code fence language extraction (→ CallInfo)

    3. Add/update tests in tests/core/parsers/test_markdown.py:
       - Test frontmatter extraction (keys parsed correctly)
       - Test table extraction (table detected, named by first column)
       - Test existing behavior preserved (headings, links, code fences)
       - Test empty file, file with only frontmatter, file with no headings

    Note: If tree-sitter-markdown doesn't expose a grammar via the standard `language()` API,
    fall back to enhanced regex parsing (keep tree-sitter attempt, fallback to regex).
    The frontmatter and table features are more important than the tree-sitter backend.

    Avoid: breaking existing markdown test behavior. Section extraction must remain compatible.
  </action>
  <verify>
    uv run python3 -m pytest tests/core/parsers/test_markdown.py -v
    uv run python3 -m pytest tests/ -x -q
  </verify>
  <done>AC-1 and AC-2 satisfied: Markdown parser has frontmatter and table support</done>
</task>

<task type="auto">
  <name>Task 2: Add Go, YAML, SQL, HTML, CSS parsers</name>
  <files>src/axon/core/parsers/go_lang.py, src/axon/core/parsers/yaml_lang.py, src/axon/core/parsers/sql_lang.py, src/axon/core/parsers/html_lang.py, src/axon/core/parsers/css_lang.py, pyproject.toml</files>
  <action>
    Create 5 new parser files following the existing pattern (see rust_lang.py as template):

    **go_lang.py** (tree-sitter-go):
    - `import tree_sitter_go as tsgo`
    - Extract: function_declaration → "function", type_declaration (struct) → "struct",
      type_declaration (interface) → "interface", method_declaration → "method" with receiver as class_name
    - Imports: import_declaration → ImportInfo
    - Calls: call_expression → CallInfo
    - Map new kind "struct" in _KIND_TO_LABEL → NodeLabel.CLASS (like Elixir's module)

    **yaml_lang.py** (NO tree-sitter — line-based like original markdown):
    - Parse YAML/TOML without tree-sitter (simple key extraction is sufficient)
    - Top-level keys: lines matching `^(\w[\w.-]*):` → SymbolInfo(kind="function")
    - Nested keys at depth 1: `  (\w[\w.-]*):` → SymbolInfo(kind="function", name="parent.child")
    - TOML: `[section]` headers → SymbolInfo(kind="function", name=section)
    - TOML: `key = value` under sections → SymbolInfo(kind="function", name="section.key")
    - Single parser class handling both formats (detect by extension or content)

    **sql_lang.py** (regex-based — SQL DDL is simple enough):
    - Regex for: CREATE TABLE name, CREATE VIEW name, CREATE FUNCTION name, CREATE PROCEDURE name
    - Each → SymbolInfo with appropriate kind ("class" for tables, "function" for functions/views/procedures)
    - DROP/ALTER as CallInfo (references to objects)
    - No tree-sitter needed — DDL patterns are well-defined

    **html_lang.py** (tree-sitter-html):
    - `import tree_sitter_html as tshtml`
    - Elements with `id` attribute → SymbolInfo(kind="function", name=id_value)
    - `<script src="...">` → ImportInfo(module=src)
    - `<link href="...">` → ImportInfo(module=href)
    - `<a href="...">` → CallInfo(name=href) for internal links

    **css_lang.py** (tree-sitter-css):
    - `import tree_sitter_css as tscss`
    - ID selectors (#name) → SymbolInfo(kind="function", name="#name")
    - Class selectors (.name) → SymbolInfo(kind="function", name=".name")
    - @import → ImportInfo(module=url)

    Add to pyproject.toml dependencies:
    - `tree-sitter-go>=0.23.0`
    - `tree-sitter-html>=0.23.0`
    - `tree-sitter-css>=0.23.0`
    (No tree-sitter deps for YAML/TOML/SQL — they use regex)

    Avoid: over-engineering parsers. These are "good enough" for code intelligence —
    extract the main symbols, imports, and calls. Don't try to parse every edge case.
  </action>
  <verify>
    python3 -c "from axon.core.parsers.go_lang import GoParser; print('Go OK')"
    python3 -c "from axon.core.parsers.yaml_lang import YamlParser; print('YAML OK')"
    python3 -c "from axon.core.parsers.sql_lang import SqlParser; print('SQL OK')"
    python3 -c "from axon.core.parsers.html_lang import HtmlParser; print('HTML OK')"
    python3 -c "from axon.core.parsers.css_lang import CssParser; print('CSS OK')"
  </verify>
  <done>AC-3, AC-4, AC-5, AC-6, AC-7 satisfied: all 5 new parsers created</done>
</task>

<task type="auto">
  <name>Task 3: Register parsers, add tests, verify full suite</name>
  <files>src/axon/config/languages.py, src/axon/core/ingestion/parser_phase.py, src/axon/core/parsers/__init__.py, tests/core/parsers/test_go.py, tests/core/parsers/test_yaml.py, tests/core/parsers/test_sql.py, tests/core/parsers/test_html.py, tests/core/parsers/test_css.py</files>
  <action>
    1. Update languages.py — add extensions:
       ```python
       ".go": "go",
       ".yml": "yaml",
       ".yaml": "yaml",
       ".toml": "toml",
       ".sql": "sql",
       ".html": "html",
       ".htm": "html",
       ".css": "css",
       ".scss": "css",
       ```

    2. Update parser_phase.py — add elif branches in get_parser():
       ```python
       elif language == "go":
           from axon.core.parsers.go_lang import GoParser
           parser = GoParser()
       elif language in ("yaml", "toml"):
           from axon.core.parsers.yaml_lang import YamlParser
           parser = YamlParser()
       elif language == "sql":
           from axon.core.parsers.sql_lang import SqlParser
           parser = SqlParser()
       elif language == "html":
           from axon.core.parsers.html_lang import HtmlParser
           parser = HtmlParser()
       elif language == "css":
           from axon.core.parsers.css_lang import CssParser
           parser = CssParser()
       ```

       Add to _KIND_TO_LABEL if needed:
       - "struct" → NodeLabel.CLASS (for Go structs — same as Elixir modules)

    3. Update parsers/__init__.py — export new parsers

    4. Create test files for each new parser:
       Each test file should have:
       - A realistic source snippet as fixture (15-30 lines)
       - Test symbol extraction (correct names, kinds, line numbers)
       - Test import extraction
       - Test call extraction (where applicable)
       - Test empty content returns empty ParseResult

       Example test structure:
       ```python
       GO_FIXTURE = """
       package main

       import "fmt"

       type User struct {
           Name string
           Age  int
       }

       func (u *User) String() string {
           return fmt.Sprintf("%s (%d)", u.Name, u.Age)
       }

       func main() {
           u := &User{Name: "Alice", Age: 30}
           fmt.Println(u.String())
       }
       """

       def test_go_functions():
           parser = GoParser()
           result = parser.parse(GO_FIXTURE, "main.go")
           names = [s.name for s in result.symbols]
           assert "main" in names
           assert "User" in names
       ```

    5. Run full test suite: `uv run python3 -m pytest tests/ -x -q`

    Avoid: writing overly complex tests. 3-5 tests per parser is sufficient.
  </action>
  <verify>
    uv run python3 -m pytest tests/core/parsers/ -v
    uv run python3 -m pytest tests/ -x -q — all 687+ existing tests plus new ones pass
  </verify>
  <done>AC-8 satisfied: all languages registered, all tests pass</done>
</task>

</tasks>

<boundaries>

## DO NOT CHANGE
- src/axon/core/parsers/base.py (LanguageParser protocol and data classes are stable)
- src/axon/core/parsers/python_lang.py (existing parser, untouched)
- src/axon/core/parsers/typescript.py (existing parser, untouched)
- src/axon/core/parsers/elixir_lang.py (existing parser, untouched)
- src/axon/core/parsers/rust_lang.py (existing parser, untouched)
- src/axon/core/storage/* (storage layer is stable from 01-02)
- src/axon/mcp/* (MCP tools untouched — plan 01-04)
- tests/e2e/* (e2e tests run as-is for regression)

## SCOPE LIMITS
- No new NodeLabel enum values — map to existing labels (FUNCTION, CLASS, METHOD, INTERFACE, etc.)
- No changes to the graph model or storage layer
- No MCP tool changes
- Parsers should be "good enough" not "perfect" — extract main symbols, imports, calls
- YAML/TOML and SQL use regex/line-based parsing (no tree-sitter)
- SCSS treated as CSS (same parser, good enough for selectors)

</boundaries>

<verification>
Before declaring plan complete:
- [ ] `grep -c "except Exception" src/axon/core/parsers/*.py` — 0 bare exceptions in new parsers
- [ ] `python3 -c "from axon.config.languages import SUPPORTED_EXTENSIONS; print(len(SUPPORTED_EXTENSIONS))"` — 20+ extensions
- [ ] `uv run python3 -m pytest tests/core/parsers/ -v` — all parser tests pass
- [ ] `uv run python3 -m pytest tests/ -x -q` — all 687+ tests plus new ones pass
- [ ] Each new parser handles empty content gracefully (returns empty ParseResult)
</verification>

<success_criteria>
- All 3 tasks completed
- All verification checks pass
- 12 languages supported: Python, TypeScript, JavaScript, Elixir, Rust, Markdown, Go, YAML, TOML, SQL, HTML, CSS
- 687+ existing tests pass with no regressions
- New parser tests all pass
</success_criteria>

<output>
After completion, create `.paul/phases/01-consolidation-and-scale/01-03-SUMMARY.md`
</output>
